<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Ashma Yonghang | TD Constrastive GCRL</title>
    <meta name="author" content="Ashma Yonghang" />
    <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
" />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>‚öõÔ∏è</text></svg>">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://ayonghan.github.io/news/announcement_2/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://ayonghan.github.io/"><span class="font-weight-bold">Ashma</span>   Yonghang</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">blog</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>

              <!-- Toogle theme mode -->
              <div class="toggle-container">
                <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </a>
              </div>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- _layouts/post.html -->

<!--<div class="post"> -->
 <article class="post-single">

  <header class="post-header">
    <h1 class="post-title">Temporal Difference Contrastive GCRL</h1>
    <p class="post-meta">September 14, 2024</p>
    <p class="post-tags">
      <a href="/blog/2024"> <i class="fas fa-calendar fa-sm"></i> 2024 </a>

    </p>
  </header>

<!--</div> -->
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#temporal-representation" aria-label="Temporal Representation">Temporal Representation</a><ul> </li>

          
                <li>
                    <a href="#contrastive-objective" aria-label="Contrastive Objective">Contrastive Objective</a>
                </li>

                <li>
                    <a href="#ranking-based-contrastive-loss" aria-label="Temporal Difference Version">Temporal Difference Version</a>
                </li>

                <li>
                      <a href="#temporal-difference-version" aria-label="Visitation Probability in Continuous Setting">Visitation Probability in Continuous Setting</a><ul></li>

              <li>
                    <a href="#visitation-probability-in-continuous-setting" aria-label="Jensen‚Äôs Inequality">Jensen‚Äôs Inequality</a><ul>

                        <li><a href="#workaround" aria-label="Workaround">Workaround</a><ul></li></ul>
                
              </li>

              <li>
                    <a href="#mathematics" aria-label="Mathematics">Mathematics</a>
              </li>

              <li>
                    <a href="#discounted-state-occupancy-measure" aria-label="Discounted State Occupancy Measure">Discounted State Occupancy Measure</a>
              </li> 

              <li>
                    <a href="#mc-infonce-estimator" aria-label="MC InfoNCE estimator">MC InfoNCE estimator</a>
              </li>

              <li>
                    <a href="#temporal-difference-infonce" aria-label="Temporal Difference InfoNCE">Temporal Difference InfoNCE</a>
              </li>       
          
              <li>
                    <a href="#goal-conditioned-policy-learning" aria-label="Goal Conditioned Policy Learning">Goal Conditioned Policy Learning</a>
              </li>
          
          </ul>
        </div>
    </details>
</div>

  <div class="post-content">
    <h2 id="temporal-representation">Temporal Representation<a hidden class="anchor" aria-hidden="true" href="#temporal-representation">#</a></h2>
    <p>To capture long-term temporal dependency: larger quantities of data is needed as  the frequency of long-term events may decrease with the time scale. In this blog, we will talk about ways to make it more sample efficient using temporal difference version of ranking-based constrastive loss.</p>
    <h2 id="contrastive-objective">Contrastive Objective<a hidden class="anchor" aria-hidden="true" href="#contrastive-objective">#</a></h2>
    <p> Two temporally close states implies transition from one state to another is more probable than states which are temporally far.</p>
    <p>In other words, distance between representations of 2 states ($s_1$, $s_2$) encodes temporal similarity , which is the state $s_1$‚Äôs probability of transitioning to the next state $s_2$ and states likely to be visited after the next state $s_2$.</p>
    
       
    <h2 id="ranking-based-contrastive-loss">Ranking-Based Contrastive Loss<a hidden class="anchor" aria-hidden="true" href="#ranking-based-contrastive-loss">#</a></h2>
    <p>Ranking version of binary classification (NCE) is info-NCE or ranking based contrastive loss.
    In info-NCE, states are ranked based on their relevance or visitation likelihood under a policy. For instance:
    </p>
    <ol>
      <li><b>Positive Pair</b>:States that are likely to be visited together under a given policy.</li>
      <li><b>Negative Pair</b>:States that are unlikely to be visited together.</li>
    </ol>

    <h2 id="temporal-difference-version">Temporal Difference Version<a hidden class="anchor" aria-hidden="true" href="#temporal-difference-version">#</a></h2>
    <p>By Incorporating Temporal Difference update into the contrastive infoNCE loss, it ensures that states are ranked not only based on current visitation likelihood but also on their future visitation likelihood under the policy. It uses the Bellman Principle of Optimality to tie the value of a state $s$ to the expected reward and the values of future states $s‚Ä≤$.
    </p>

    <p>TD version of info-NCE loss enables us to use data from one policy to estimate which states a different policy will visit because they rely on transition probabilities and rewards, which are typically shared across policies in a given environment. This allows the model to infer visitation patterns of a new policy based on the data collected from another.
    </p>
      
    <h2 id="visitation-probability-in-continuous-setting">Visitation Probability in Continuous Setting<a hidden class="anchor" aria-hidden="true" href="#visitation-probability-in-continuous-setting">#</a></h2>
    <p>In tabular settings, computing visitation probability is manageable because the states are discrete, and we can compute expected number of times state s‚Ä≤s's‚Ä≤ will be visited starting from state sss and following policy œÄ\piœÄ.number of times state s‚Ä≤s's‚Ä≤ will be visited starting from state sss and following policy œÄ\piœÄ. for each pair of states directly. However, in continuous spaces, representing and estimating this matrix becomes computationally infeasible due to infinite possible states.
    </p>
    
    <h4 id="workaround">Workaround<a hidden class="anchor" aria-hidden="true" href="#workaround">#</a></h4>
    <p>Instead of directly estimating visitation probabilities (or their discounted sums), the idea is to learn state representations in a latent space where the inner product between two state embeddings approximates the visitation probability. Learning a latent space allows the model to generalize across unseen states by leveraging the learned structure of the environment.</p>
    

    <h2 id="mathematics">Mathematics<a hidden class="anchor" aria-hidden="true" href="#mathematics">#</a></h2>
    <p>Self-supervised actor critic algorithm is used. Similarity function f between two representations is a parametric function - parameterized by inner product of representations of data, /phi(.) and /psi(.) map 
data to $\mathcal{L_{2}}$ normalized vectors of dimension d. f is a critic function, $/phi$ and $/psi$ are contrastive representations of x and y respectively.
    </p>

    <p>Bayes-optimal critic of f is denotes as f* and given by: $$exp(f*(x,y)) = \frac{p(y \mid x)}{p(y)c(x)}$$
      Here, c(.) is arbitrary function estimated as the reciprocal of optimal critic over negative pairs sampled from the distribution.
    $$
    \mathbb{E}_{p(y)} \left[ \exp(f^{\star}(x, y)) \right] = \int p(y) \frac{p(y \mid x)} {p(y) c(x)} \, dy =  \frac{1}{c(x)} \, \int p(y \mid x) \, dy = \frac{1}{c(x)}
    $$
  </p>

    

    <h2 id="discounted-state-occupancy-measure">Discounted State Occupancy Measure<a hidden class="anchor" aria-hidden="true" href="#deriving-the-variational-bound-elbo">#</a></h2>
    <p>quantifies the "importance" or "likelihood" of being in a particular state 
$ùë†t+$  under a specific policy, while considering the discounted nature of rewards (or contributions) over time.
      $$p_{\pi}(s_{t+} \mid s, a) \coloneqq (1 - \gamma) \sum_{t=1}^{\infty} \gamma^{t-1} p_{\pi}^{t}(s_{t+} \mid s, a)$$


      The normalization factor $(1 - \gamma)$ ensures that the discounted sum is properly normalized across time i.e. it adds up to 1.Without this factor, the infinite summation could diverge or be incorrectly scaled depending on the choice of Œ≥. This factor arises naturally in discounted sums and ensures consistency with the total probability.
</p>

    <h2 id="mc-infonce-estimator">MC InfoNCE estimator<a hidden class="anchor" aria-hidden="true" href="#mc-infonce-estimator">#</a></h2>
    <p>Prior works like contrastive RL and c-learning also aim to learn representations whose inner products correspond to the likelihoods of reaching future states.
But it uses Monte Carlo estimator which has high variance and is sample inefficient as compared to TD methods. Expression for monte carlo info-NCE estimator:
$$
\text{L_{MCInfoNCE}(f)} = \mathbb{E}_{(s, a) \sim p(s, a), s_{t+}^{(1)} \sim p_{\pi}(s_{t+} \mid s, a), s_{t+}^{(2:N)} \sim p(s_{t+})} \left[  \log \log(\frac{\exp(f(s, a, s_{t+}^{(1)}))}{\sum_{i=1}^{N} \exp(f(s, a, s_{t+}^{(i)}))}) \right]
$$

      Optimal critic $f^{\star}$ is expressed as:
      $$
\exp(f^{\star}(s, a, s_{t+})) = \frac{p^{\pi}(s_{t+} \mid s, a)]{\, p(s_{t+}) \, c(s, a)}
$$
</p>


    <h2 id="temporal-difference-infonce">Temporal Difference InfoNCE<a hidden class="anchor" aria-hidden="true" href="#solution-reparameterization-trick">#</a></h2>
    <p>We avoid sampling from discounted state occupancy measure of policy œÄ by using importance sampling - sampling is then done over $p(s_{t+})$.
    </p>
    
    <h2 id="goal-conditioned-policy-learning">Goal Conditioned Policy Learning<a hidden class="anchor" aria-hidden="true" href="#goal-conditioned-policy-learning">#</a></h2>
    <p>TD InfoNCE loss as stated above estimates the discounted state occupancy measure for policy œÄ(a | s). 
      It can be extended to the goal-conditioned setting by replacing $\pi(a \mid s)$ with  $\pi(a \mid s, g)$ and $f(s, a, s_{t+})$ with $f(s, a, g, s_{t+})$, resulting in a goal-conditioned TD InfoNCE estimator.
    </p>
    
        

  </div>
  </article>

</div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        ¬© Copyright 2022 Ashma  Yonghang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true,
      tags: 'all' 
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };

  window.addEventListener('load', (event) => {
      document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax'})
    });

</script>
  <script defer type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>
